"""Add interaction_type to LLM interactions

Revision ID: 7c617b3e7c2c
Revises: ae85467a75d2
Create Date: 2025-10-03 12:15:54.424780

"""

from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = "7c617b3e7c2c"
down_revision: Union[str, Sequence[str], None] = "ae85467a75d2"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # Check if column already exists (for idempotency with baseline migration)
    from sqlalchemy import inspect
    connection = op.get_bind()
    inspector = inspect(connection)
    
    # Get existing columns
    existing_columns = {col['name'] for col in inspector.get_columns('llm_interactions')}
    
    # Only add column if it doesn't exist
    if 'interaction_type' not in existing_columns:
        # ### commands auto generated by Alembic - please adjust! ###
        with op.batch_alter_table("llm_interactions", schema=None) as batch_op:
            batch_op.add_column(
                sa.Column(
                    "interaction_type",
                    sa.String(length=50),
                    server_default="investigation",
                    nullable=False,
                )
            )

        # ### end Alembic commands ###
        
        # Backfill existing records with correct interaction types (only if column was added)
        # Identify summarization interactions (system message contains summarization marker)
        # Check for the specific system message content that only appears in summarization calls
        dialect_name = connection.dialect.name
        
        if dialect_name == 'postgresql':
            # PostgreSQL: Cast JSONB to text for LIKE operator
            connection.execute(sa.text("""
                UPDATE llm_interactions 
                SET interaction_type = 'summarization'
                WHERE CAST(conversation AS text) LIKE '%You are an expert at summarizing technical output%'
            """))
        else:
            # SQLite: conversation is already TEXT
            connection.execute(sa.text("""
                UPDATE llm_interactions 
                SET interaction_type = 'summarization'
                WHERE conversation LIKE '%You are an expert at summarizing technical output%'
            """))
        
        # Identify final_analysis interactions (last assistant message contains "Final Answer:")
        # For PostgreSQL with JSONB - check if last assistant message starts with "Final Answer:"
        # For SQLite - use JSON1 functions with proper casting
        
        if dialect_name == 'postgresql':
            connection.execute(sa.text("""
                UPDATE llm_interactions 
                SET interaction_type = 'final_analysis'
                WHERE interaction_type != 'summarization'
                AND EXISTS (
                    SELECT 1 FROM (
                        SELECT 
                            msg->>'content' as content,
                            ROW_NUMBER() OVER (ORDER BY ordinality DESC) as rn
                        FROM jsonb_array_elements(conversation->'messages') WITH ORDINALITY AS msg
                        WHERE msg->>'role' = 'assistant'
                    ) last_assistant
                    WHERE last_assistant.rn = 1
                    AND (
                        last_assistant.content LIKE 'Final Answer:%'
                        OR last_assistant.content LIKE '% Final Answer:%'
                        OR last_assistant.content LIKE '%' || CHR(10) || 'Final Answer:%'
                    )
                )
            """))
        else:
            # SQLite - JSON-based detection using json_extract (no ->> operator in SQLite)
            connection.execute(sa.text("""
                UPDATE llm_interactions 
                SET interaction_type = 'final_analysis'
                WHERE interaction_type != 'summarization'
                AND interaction_id IN (
                    SELECT llm.interaction_id
                    FROM llm_interactions llm,
                         json_each(json_extract(llm.conversation, '$.messages')) msg
                    WHERE json_extract(msg.value, '$.role') = 'assistant'
                    AND CAST(msg.key AS INTEGER) = (
                        SELECT MAX(CAST(m2.key AS INTEGER))
                        FROM json_each(json_extract(llm.conversation, '$.messages')) m2
                        WHERE json_extract(m2.value, '$.role') = 'assistant'
                        AND m2.value IS NOT NULL
                    )
                    AND (
                        json_extract(msg.value, '$.content') LIKE 'Final Answer:%'
                        OR json_extract(msg.value, '$.content') LIKE '%' || CHAR(10) || 'Final Answer:%'
                    )
                )
            """))
        
        # Explicitly set remaining records to 'investigation' (don't rely on default)
        connection.execute(sa.text("""
            UPDATE llm_interactions 
            SET interaction_type = 'investigation'
            WHERE interaction_type NOT IN ('summarization', 'final_analysis')
        """))


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("llm_interactions", schema=None) as batch_op:
        batch_op.drop_column("interaction_type")

    # ### end Alembic commands ###
